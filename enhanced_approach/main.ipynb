{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdff91e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (5.1.1)\n",
      "Requirement already satisfied: hdbscan in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (0.8.40)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (0.5.9.post2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.56.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from hdbscan) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from umap-learn) (0.61.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.44.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (72.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pawanmagapalli\\anaconda3\\lib\\site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf pytesseract pillow sentence-transformers hdbscan umap-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a338545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text and features from pages...\n"
     ]
    },
    {
     "ename": "PatternError",
     "evalue": "incomplete escape \\U at position 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPatternError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    100\u001b[0m     pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPawanMagapalli\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDoc-Classification\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmerged doc.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your PDF path\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     detected_docs, cluster_labels, texts \u001b[38;5;241m=\u001b[39m process_pdf(pdf_path)\n",
      "Cell \u001b[1;32mIn[3], line 45\u001b[0m, in \u001b[0;36mprocess_pdf\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m     43\u001b[0m     text \u001b[38;5;241m=\u001b[39m extract_text_from_page(page)\n\u001b[0;32m     44\u001b[0m     page_texts\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[1;32m---> 45\u001b[0m     pattern_features\u001b[38;5;241m.\u001b[39mappend(extract_features(text))\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Get embeddings for all page texts\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing text embeddings...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 26\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     24\u001b[0m has_title \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^[A-Z][A-Za-z\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m3,}\u001b[39m\u001b[38;5;124m'\u001b[39m, text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     25\u001b[0m has_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2}[-/]\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2}[-/]\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m2,4}\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, text) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 26\u001b[0m has_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPawanMagapalli\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDoc-Classification\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule_based_approach\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mrule.yml\u001b[39m\u001b[38;5;124m'\u001b[39m, text, re\u001b[38;5;241m.\u001b[39mI) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([word_count, has_title, has_date, has_signature])\n",
      "File \u001b[1;32mc:\\Users\\PawanMagapalli\\anaconda3\\Lib\\re\\__init__.py:177\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "File \u001b[1;32mc:\\Users\\PawanMagapalli\\anaconda3\\Lib\\re\\__init__.py:350\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _compiler\u001b[38;5;241m.\u001b[39misstring(pattern):\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst argument must be string or compiled pattern\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m p \u001b[38;5;241m=\u001b[39m _compiler\u001b[38;5;241m.\u001b[39mcompile(pattern, flags)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m DEBUG:\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mc:\\Users\\PawanMagapalli\\anaconda3\\Lib\\re\\_compiler.py:748\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 748\u001b[0m     p \u001b[38;5;241m=\u001b[39m _parser\u001b[38;5;241m.\u001b[39mparse(p, flags)\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    750\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PawanMagapalli\\anaconda3\\Lib\\re\\_parser.py:980\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    977\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[0;32m    978\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m--> 980\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    981\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\PawanMagapalli\\anaconda3\\Lib\\re\\_parser.py:459\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    457\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 459\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    460\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PawanMagapalli\\anaconda3\\Lib\\re\\_parser.py:543\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 543\u001b[0m     code \u001b[38;5;241m=\u001b[39m _escape(source, this, state)\n\u001b[0;32m    544\u001b[0m     subpatternappend(code)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SPECIAL_CHARS:\n",
      "File \u001b[1;32mc:\\Users\\PawanMagapalli\\anaconda3\\Lib\\re\\_parser.py:397\u001b[0m, in \u001b[0;36m_escape\u001b[1;34m(source, escape, state)\u001b[0m\n\u001b[0;32m    395\u001b[0m escape \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mgetwhile(\u001b[38;5;241m8\u001b[39m, HEXDIGITS)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(escape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincomplete escape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m escape, \u001b[38;5;28mlen\u001b[39m(escape))\n\u001b[0;32m    398\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(escape[\u001b[38;5;241m2\u001b[39m:], \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28mchr\u001b[39m(c) \u001b[38;5;66;03m# raise ValueError for invalid code\u001b[39;00m\n",
      "\u001b[1;31mPatternError\u001b[0m: incomplete escape \\U at position 2"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan\n",
    "import umap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# --- Step 1: Extract text with OCR fallback ---\n",
    "def extract_text_from_page(page):\n",
    "    text = page.get_text().strip()\n",
    "    if len(text) < 20:  # If text is too short, try OCR\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "# --- Step 2: Extract additional features from text ---\n",
    "def extract_features(text):\n",
    "    # Basic pattern features\n",
    "    word_count = len(text.split())\n",
    "    has_title = 1 if re.search(r'^[A-Z][A-Za-z\\s]{3,}', text.split('\\n')[0]) else 0\n",
    "    has_date = 1 if re.search(r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b', text) else 0\n",
    "    has_signature = 1 if re.search(r'(Sincerely|Regards|Best regards|Thank you)', text, re.I) else 0\n",
    "    return np.array([word_count, has_title, has_date, has_signature])\n",
    "\n",
    "# --- Main processing function ---\n",
    "def process_pdf(pdf_path):\n",
    "    # Load model for embeddings\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Open PDF\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "    page_texts = []\n",
    "    pattern_features = []\n",
    "\n",
    "    print(\"Extracting text and features from pages...\")\n",
    "    for i in range(len(pdf_document)):\n",
    "        page = pdf_document[i]\n",
    "        text = extract_text_from_page(page)\n",
    "        page_texts.append(text)\n",
    "        pattern_features.append(extract_features(text))\n",
    "\n",
    "    # Get embeddings for all page texts\n",
    "    print(\"Computing text embeddings...\")\n",
    "    embeddings = model.encode(page_texts)\n",
    "\n",
    "    # Normalize pattern features and scale down to balance with embeddings\n",
    "    pattern_features = np.array(pattern_features)\n",
    "    pattern_features = (pattern_features - pattern_features.mean(axis=0)) / (pattern_features.std(axis=0) + 1e-6)\n",
    "    pattern_features_scaled = pattern_features * 0.5  # scale factor to balance features and embeddings\n",
    "\n",
    "    # Combine embeddings and pattern features\n",
    "    combined_features = np.hstack([embeddings, pattern_features_scaled])\n",
    "\n",
    "    # Cluster pages with HDBSCAN\n",
    "    print(\"Clustering pages...\")\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=2, metric='euclidean')\n",
    "    clusters = clusterer.fit_predict(combined_features)\n",
    "\n",
    "    # Merge consecutive pages with same cluster label into documents\n",
    "    docs = []\n",
    "    current_doc = []\n",
    "    current_cluster = clusters[0]\n",
    "\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        if cluster_id == current_cluster:\n",
    "            current_doc.append(idx)\n",
    "        else:\n",
    "            docs.append(current_doc)\n",
    "            current_doc = [idx]\n",
    "            current_cluster = cluster_id\n",
    "    docs.append(current_doc)\n",
    "\n",
    "    # Print detected documents\n",
    "    print(\"\\nDetected documents and their page ranges:\")\n",
    "    for i, doc_pages in enumerate(docs):\n",
    "        print(f\"Document {i+1}: pages {doc_pages}\")\n",
    "\n",
    "    # Visualization with UMAP\n",
    "    print(\"\\nVisualizing clusters with UMAP...\")\n",
    "    reducer = umap.UMAP(n_neighbors=5, min_dist=0.3, metric='euclidean', random_state=42)\n",
    "    embedding_2d = reducer.fit_transform(combined_features)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    scatter = plt.scatter(embedding_2d[:, 0], embedding_2d[:, 1], c=clusters, cmap='tab20', s=60)\n",
    "    plt.colorbar(scatter, label='Cluster ID')\n",
    "    plt.title(\"Page Clusters Visualization (UMAP)\")\n",
    "    plt.xlabel(\"UMAP Dimension 1\")\n",
    "    plt.ylabel(\"UMAP Dimension 2\")\n",
    "    plt.show()\n",
    "\n",
    "    return docs, clusters, page_texts\n",
    "\n",
    "# --- Run on your PDF file ---\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r\"C:\\Users\\PawanMagapalli\\Downloads\\document\\Doc-Classification\\merged doc.pdf\"  # Replace with your PDF path\n",
    "    detected_docs, cluster_labels, texts = process_pdf(pdf_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
